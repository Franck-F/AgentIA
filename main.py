import os
import re
import streamlit as st
import pandas as pd
from datetime import datetime
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_chroma import Chroma
import chromadb
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.retrievers.multi_query import MultiQueryRetriever
from rank_bm25 import BM25Okapi
from langchain.schema import BaseRetriever, Document
import hashlib
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field, validator, PrivateAttr
import traceback 

# --- Configuration S√©curis√©e de la Cl√© API ---
try:
    os.environ["GOOGLE_API_KEY"] = 'AIzaSyBLhTbSnCpyPFl_SeHI2zd9gRrKa9M1Ssg'
except KeyError:
    if "GOOGLE_API_KEY" not in os.environ:
        print("Cl√© API Google (GOOGLE_API_KEY) non trouv√©e. Veuillez la configurer dans les secrets Streamlit ou les variables d'environnement.")
        
    
# Initialisation de ChromaDB
CHROMA_DB_PATH = "./chroma_db"
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    chroma_collection = chroma_client.get_or_create_collection("rag_chatbot")
except Exception as e:
    print(f"Erreur lors de l'initialisation de ChromaDB √† {CHROMA_DB_PATH}: {e}")
    
    
# chargement et indexation des donn√©es
@st.cache_resource(show_spinner="Chargement et indexation des documents...")
def load_and_index_pdfs(directory, persist_directory):
    try:
        loader = DirectoryLoader(directory, loader_cls=PyPDFLoader, show_progress=True)
        documents = loader.load()
        if not documents:
            st.warning(f"Aucun document PDF trouv√© dans le dossier : {directory}")
            return None
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        texts = text_splitter.split_documents(documents)

        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

        db = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)
        print(f"{len(texts)} chunks index√©s avec succ√®s.")
        return db
    except Exception as e:
        st.error(f"Erreur lors du chargement/indexation des PDFs: {e}")
        return None

# Chargement des documents ou de la base existante

pdf_directory = "data/pdfs"
vector_db = None

# V√©rifier si la base de donn√©es existe d√©j√†
if os.path.exists(CHROMA_DB_PATH):
    try:
        print(f"Chargement de la base vectorielle depuis {CHROMA_DB_PATH}...")
        vector_db = Chroma(persist_directory=CHROMA_DB_PATH,
                           embedding_function=GoogleGenerativeAIEmbeddings(model="models/embedding-001"))
        print("Base vectorielle charg√©e.")
    except Exception as e:
        st.warning(f"Erreur lors du chargement de la base existante: {e}. Tentative de r√©indexation...")
        vector_db = None 

# Si la base n'a pas √©t√© charg√©e (ou erreur), tenter de la cr√©er/r√©indexer
if vector_db is None:
    if os.path.exists(pdf_directory) and os.listdir(pdf_directory):
        vector_db = load_and_index_pdfs(pdf_directory, CHROMA_DB_PATH)
    else:
        st.warning(f"Le dossier PDF '{pdf_directory}' est vide ou n'existe pas. Aucune donn√©e √† indexer.")
        # Initialiser une base vectorielle vide
        try:
             vector_db = Chroma(persist_directory=CHROMA_DB_PATH,
                                embedding_function=GoogleGenerativeAIEmbeddings(model="models/embedding-001"))
             st.info("Base vectorielle vide initialis√©e.")
        except Exception as e:
             st.error(f"Impossible d'initialiser une base vectorielle vide: {e}")
             st.stop()


# --- V√©rification si vector_db a √©t√© correctement initialis√© ---
if vector_db is None:
    st.error("Impossible de charger ou cr√©er la base de donn√©es vectorielle. L'application ne peut pas continuer.")
    st.stop()


# D√©finition du prompt 
QUERY_PROMPT = PromptTemplate(
    input_variables=["question"],
    template="""R√¥le & Mission
Tu es un assistant virtuel sp√©cialis√© dans l‚Äôorientation acad√©mique et professionnelle des √©l√®ves et √©tudiants en France.
Ton objectif est de les guider dans :
‚Ä¢ Le choix de leurs √©tudes et de leur carri√®re en fonction de leurs int√©r√™ts et comp√©tences.
‚Ä¢ L‚Äôanalyse des offres de formation et d‚Äôemploi pour identifier celles qui leur correspondent le mieux.
‚Ä¢ L‚Äôaccompagnement dans la r√©daction de documents essentiels :
  o Lettres de motivation.
  o Projets de formation motiv√©s (notamment pour Parcoursup).
  o CV et autres documents de candidature.
‚Ä¢ Le suivi des candidatures, en aidant √† organiser un journal de candidatures et √† optimiser leurs d√©marches.
Tu dois toujours fournir des informations pr√©cises, adapt√©es et √† jour, exclusivement pour la France.

M√©thodologie de r√©ponse
Lorsqu‚Äôun utilisateur pose une question, tu dois :
1. Comprendre pr√©cis√©ment la demande et poser des questions de clarification si n√©cessaire.
2. Fournir une r√©ponse claire, d√©taill√©e et adapt√©e au niveau et au contexte de l‚Äôutilisateur.
3. S‚Äôadapter au ton de l‚Äôutilisateur.
4. Structurer tes r√©ponses pour une meilleure lisibilit√© (ex: listes √† puces).
5. Ne pas inventer d‚Äôinformations. Si tu ne sais pas, dis-le clairement.
6. Utiliser le contexte fourni pour r√©pondre.

Exemples de demandes
‚Ä¢ "Peux-tu m'expliquer comment fonctionne Parcoursup ?"
‚Ä¢ "Comment structurer une lettre de motivation efficace ?"
‚Ä¢ "Quelle est la r√©mun√©ration d‚Äôun apprenti en France ?"
‚Ä¢ "propose moi des formations apr√®s le baccalaur√©at "


Limites et restrictions
1. Pas de conseils m√©dicaux ou juridiques.
2. Pas d‚Äô√©v√©nements r√©cents au-del√† de la date de mise √† jour des donn√©es.
3. Pas d‚Äôopinions personnelles ou d‚Äô√©motions.

Question: {question}""", 
)


# Cr√©ation d'un retriever personnalis√© avec BM25
class BM25EnhancedRetriever(BaseRetriever):
    _vectorstore: Chroma = PrivateAttr()
    _k: int = PrivateAttr()
    _base_retriever: BaseRetriever = PrivateAttr()
    _bm25: BM25Okapi = PrivateAttr(default=None)
    _corpus: List[str] = PrivateAttr(default=None)
    _docs_map: List[Document] = PrivateAttr(default=None)

    def __init__(self, vectorstore: Chroma, k: int = 4):
        super().__init__()
        self._vectorstore = vectorstore
        self._k = k
    
        # --- Augmenter k pour le retriever de base pour avoir plus de candidats pour BM25 ---
        self._base_retriever = vectorstore.as_retriever(search_kwargs={"k": k * 5})

    def _initialize_bm25(self, docs: List[Document]):
        """Initialise ou met √† jour l'index BM25."""
        self._docs_map = docs
        self._corpus = [doc.page_content for doc in docs]
        tokenized_corpus = [doc.split() for doc in self._corpus]
        self._bm25 = BM25Okapi(tokenized_corpus)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # R√©cup√©rer un plus grand nombre de documents initiaux
        initial_docs = self._base_retriever.get_relevant_documents(query)
        if not initial_docs:
            return []

        self._initialize_bm25(initial_docs)

        # Tokeniser la requ√™te
        tokenized_query = query.split()

        # Calculer les scores BM25
        bm25_scores = self._bm25.get_scores(tokenized_query)

        # Combiner documents et scores
        scored_docs = list(zip(self._docs_map, bm25_scores))

        # Trier par score BM25 (d√©croissant)
        scored_docs.sort(key=lambda x: x[1], reverse=True)

        # Retourner les k meilleurs documents uniques
        final_docs = []
        seen_content = set()
        for doc, score in scored_docs:
            if len(final_docs) >= self._k:
                break
            # --- √âviter les doublons bas√©s sur le contenu ---
            if doc.page_content not in seen_content:
                final_docs.append(doc)
                seen_content.add(doc.page_content)


        return final_docs

    async def _aget_relevant_documents(self, query: str) -> List[Document]:
        return self.get_relevant_documents(query)

# --- Initialisation du LLM avec gestion d'erreur ---
try:
    # LLM pour g√©n√©rer des requ√™tes alternatives pour le retriever
    llm_for_retriever = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0, max_tokens=500)

    # LLM principal pour la g√©n√©ration de r√©ponse
    main_llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0.7, max_tokens=500)

    # LLM pour les fonctions utilitaires (clarification, etc.)
    llm_utils = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0.5, max_tokens=500) 

except Exception as e:
    st.error(f"Erreur lors de l'initialisation des mod√®les Google Generative AI: {e}")
    st.stop()


# --- Initialisation du Retriever avec gestion d'erreur ---
try:
    retriever = MultiQueryRetriever.from_llm(
        retriever=BM25EnhancedRetriever(vector_db, k=4), 
        llm=llm_for_retriever,
        prompt=QUERY_PROMPT 
    )
except Exception as e:
    st.error(f"Erreur lors de l'initialisation du MultiQueryRetriever: {e}")
    st.stop()


# RAG prompt template
template = """R√©pond √† la question de l'utilisateur en te basant UNIQUEMENT sur le contexte suivant. Si le contexte ne contient pas la r√©ponse, dis que tu ne sais pas. Ne fais pas r√©f√©rence au contexte dans ta r√©ponse finale.

Contexte:
{context}

Question: {query}

R√©ponse:
""" 

prompt = ChatPromptTemplate.from_template(template)


# Cr√©ation de la cha√Æne RAG
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | main_llm 
    | StrOutputParser()
)

# --- Fonctions utilitaires ---

# Fonction pour d√©tecter si une question de clarification est n√©cessaire
def needs_clarification(query):
    clarification_prompt = ChatPromptTemplate.from_template("""
    Analyse la question suivante de l'utilisateur. L'utilisateur cherche des informations sur l'orientation scolaire et professionnelle en France.
    La question est-elle suffisamment pr√©cise pour y r√©pondre directement ou est-elle trop vague/manque de contexte (par exemple, l'utilisateur demande "des formations" sans pr√©ciser de domaine, de niveau, etc.)?

    Question: {query}

    R√©ponds par "True" si la question est vague ou n√©cessite plus de contexte pour une r√©ponse utile.
    R√©ponds par "False" si la question est claire et sp√©cifique.
    R√©ponse (True/False uniquement):
    """)
    try:
        clarif_chain = clarification_prompt | llm_utils | StrOutputParser()
        response = clarif_chain.invoke({"query": query})
        # --- V√©rification plus robuste de la r√©ponse ---
        return response.strip().lower() == "true"
    except Exception as e:
        st.warning(f"Erreur dans needs_clarification: {e}")
        return False 

# Fonction pour g√©n√©rer des questions de clarification
def generate_clarifying_questions(query):
    question_prompt = ChatPromptTemplate.from_template("""
    En tant qu'assistant d'orientation, g√©n√®re 2 ou 3 questions pertinentes et concises pour aider l'utilisateur √† pr√©ciser sa demande suivante. Les questions doivent viser √† obtenir des informations manquantes (domaine d'int√©r√™t, niveau d'√©tudes, pr√©f√©rences, etc.).

    Demande de l'utilisateur:
    {query}

    Format: Retourne uniquement les questions, une par ligne, commen√ßant par un tiret (-). Ne num√©rote pas les questions.
    Exemple:
    - Quel domaine d'√©tudes vous int√©resse ?
    - Quel est votre niveau d'√©tudes actuel ?
    """)
    try:
        gen_q_chain = question_prompt | llm_utils | StrOutputParser()
        response = gen_q_chain.invoke({"query": query})
        # --- Nettoyage pour s'assurer que ce sont bien des questions ---
        questions = [q.strip() for q in response.strip().split('\n') if q.strip().startswith('-')]
        return questions if questions else ["Pourriez-vous pr√©ciser votre demande ?"] # Fallback
    except Exception as e:
        st.warning(f"Erreur dans generate_clarifying_questions: {e}")
        return ["Pourriez-vous pr√©ciser votre demande ?"] # Fallback

# Fonction pour nettoyer la r√©ponse
def clean_response(response):
    if not response or response.strip() == "":
        return "Je n'ai pas trouv√© de r√©ponse pertinente √† votre question dans les documents disponibles. Pourriez-vous la reformuler ou me donner plus de d√©tails ?"
    cleaned = re.sub(r"```json\s*(.*?)\s*```", r"\1", response, flags=re.DOTALL)
    cleaned = re.sub(r"Je ne dispose pas d'informations √† ce sujet.*", "", cleaned, flags=re.IGNORECASE).strip()
    cleaned = re.sub(r"Je ne peux pas r√©pondre √† cette question.*", "", cleaned, flags=re.IGNORECASE).strip()
    
    if not cleaned:
         return "Je n'ai pas trouv√© de r√©ponse pertinente √† votre question dans les documents disponibles. Pourriez-vous la reformuler ou me donner plus de d√©tails ?"
    return cleaned.strip()

# Fonction pour d√©tecter les formules de politesse 
def detect_greeting(text):
    greetings = {
        "bonjour": "Bonjour",
        "bonsoir": "Bonsoir",
        "salut": "Salut",
        "hey": "Hey",
        "coucou": "Coucou",
        "hello": "Hello"
    }
    first_words = text.lower().split()[:2]
    for word in first_words:
        cleaned_word = re.sub(r'[^\w\s]', '', word) 
        if cleaned_word in greetings:
            return greetings[cleaned_word]
    return None



# Fonction principale de conversation
def conversation_chat(query):
    try:
        # V√©rifier les salutations simples
        greeting = detect_greeting(query)
        if greeting and len(query.split()) <= 2:
            return {
                "response": f"{greeting}, comment puis-je vous aider aujourd'hui ?",
                "needs_clarification": False
            }

        # G√©rer les r√©ponses aux questions de clarification
        if st.session_state.get('awaiting_clarification', False):
            # Ajouter la r√©ponse de l'utilisateur au contexte de clarification
            st.session_state.clarification_context.append(query)
            # Construire une requ√™te combin√©e plus naturelle
            combined_query = f"Ma question initiale √©tait : '{st.session_state.original_query}'. Voici mes pr√©cisions : {' '.join(st.session_state.clarification_context)}"
            st.info("Merci pour ces pr√©cisions. Recherche en cours...")

            # Utiliser la cha√Æne RAG principale avec la requ√™te combin√©e
            with st.spinner("R√©flexion avec les pr√©cisions..."):
                final_response = chain.invoke(combined_query) # Utilise la cha√Æne RAG

            # R√©initialiser l'√©tat d'attente
            st.session_state.awaiting_clarification = False
            st.session_state.original_query = None
            st.session_state.clarification_context = []

            return {
                "response": clean_response(final_response),
                "needs_clarification": False
            }

        # V√©rifier si la nouvelle question n√©cessite clarification AVANT d'appeler la cha√Æne RAG
        if needs_clarification(query):
            st.session_state.awaiting_clarification = True
            st.session_state.original_query = query
            st.session_state.clarification_context = [] # R√©initialiser le contexte
            clarifying_questions = generate_clarifying_questions(query)
            # --- Formatage am√©lior√© des questions ---
            response_text = "Pour mieux vous aider, pourriez-vous pr√©ciser les points suivants ?\n\n" + "\n".join(clarifying_questions)
            return {
                "response": response_text,
                "needs_clarification": True
            }

        # Question directe (utiliser la cha√Æne RAG principale)
        with st.spinner("Recherche d'informations et g√©n√©ration de la r√©ponse..."):
            response_content = chain.invoke(query) # Utilise la cha√Æne RAG

        final_response_text = clean_response(response_content)

        # Ajouter la salutation si d√©tect√©e dans une question plus longue
        if greeting and not final_response_text.lower().startswith(greeting.lower()):
             final_response_text = f"{greeting} ! {final_response_text}"

        return {
            "response": final_response_text,
            "needs_clarification": False
        }

    except Exception as e:
        # --- AJOUT POUR LE DEBUG ---
        print(f"ERREUR D√âTAILL√âE dans conversation_chat: {e}")
        import traceback
        traceback.print_exc() # Affiche la trace compl√®te de l'erreur
        # --- FIN DE L'AJOUT ---
        st.error(f"Une erreur est survenue lors du traitement de votre demande: {str(e)}")
        return {
            "response": "Je suis d√©sol√©, une erreur technique m'emp√™che de r√©pondre. Veuillez r√©essayer.",
            "needs_clarification": False
        }


# Initialisation des variables de session 
if "messages" not in st.session_state:
    st.session_state.messages = []
if "awaiting_clarification" not in st.session_state:
    st.session_state.awaiting_clarification = False
if "original_query" not in st.session_state:
    st.session_state.original_query = None
if "clarification_context" not in st.session_state:
    st.session_state.clarification_context = []
    
    
    
    
    

# Configuration de la page Streamlit 
st.set_page_config(
    page_title="Bacc2Future", # Correction nom
    page_icon=":book:",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s (Correction des > et <)
st.markdown("""
<style>
/* Styles g√©n√©raux */
body {
    font-family: 'Arial', sans-serif; /* Police plus standard */
}

/* Conteneur principal */
.main .block-container {
    padding-top: 2rem;
    padding-bottom: 5rem; /* Espace pour le chat input fixe */
}

/* Titre et description */
h1, .stMarkdown p:first-of-type {
    text-align: center;
    margin-bottom: 1.5rem;
}
h1 {
    color: #1565C0; /* Couleur bleue pour le titre */
}

/* Conteneur de chat */
.chat-container {
    display: flex;
    margin-bottom: 1rem;
    align-items: flex-start;
    max-width: 850px; /* L√©g√®rement plus large */
    margin-left: auto;
    margin-right: auto;
}

/* Alignement des messages */
.user-message {
    justify-content: flex-start;
}
.assistant-message {
    justify-content: flex-start;
}

/* Avatars */
.avatar {
    width: 40px;
    height: 40px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-right: 10px; /* Espace entre avatar et message */
    font-size: 20px;
    flex-shrink: 0;
    order: 0; /* Avatar toujours √† gauche */
}
.user-avatar {
    background-color: #E8F5E9; /* Vert clair */
    color: #2E7D32; /* Vert fonc√© */
    border: 1px solid #A5D6A7; /* Bordure verte plus douce */
}
.assistant-avatar {
    background-color: #E3F2FD; /* Bleu clair */
    color: #1565C0; /* Bleu fonc√© */
    border: 1px solid #90CAF9; /* Bordure bleue plus douce */
}

/* Contenu des messages */
.message-content {
    padding: 0.8rem 1.2rem; /* Padding ajust√© */
    border-radius: 18px; /* Coins plus arrondis */
    max-width: calc(100% - 50px); /* Largeur max ajust√©e */
    word-wrap: break-word;
    order: 1; /* Contenu √† droite de l'avatar */
    box-shadow: 0 1px 3px rgba(0,0,0,0.05); /* Ombre l√©g√®re */
}
.user-content {
    background-color: #FFFFFF; /* Fond blanc pour l'utilisateur */
    color: #333;
    border: 1px solid #e0e0e0;
    /* align-self: flex-end; /* Pourrait √™tre utilis√© pour aligner √† droite si souhait√© */
}
.assistant-content {
    background-color: #F1F8FF; /* Fond bleu tr√®s clair pour l'assistant */
    color: #333;
    border: 1px solid #d1e6ff;
}

/* Champ de saisie */
.stTextInput > div > div > input {
    border-radius: 20px;
    border: 1px solid #ccc;
    padding: 10px 15px;
}
/* Style pour le conteneur du chat_input pour le fixer en bas (optionnel) */
/* div[data-testid="stChatInput"] {
    position: fixed;
    bottom: 0;
    width: 100%;
    background-color: white;
    padding: 10px 0;
    z-index: 1000;
    border-top: 1px solid #eee;
} */

/* Style des onglets */
div[data-baseweb="tab-list"] {
    justify-content: center; /* Centrer les onglets */
    margin-bottom: 1.5rem;
}
button[data-baseweb="tab"] {
    font-size: 1rem;
    padding: 10px 20px;
}

</style>
""", unsafe_allow_html=True)

st.markdown("<h1>üìñ Bacc2Future - Assistant d'orientation acad√©mique</h1>", unsafe_allow_html=True)
st.markdown("<p>Bienvenue sur Bacc2Future, votre assistant pour l'orientation acad√©mique et professionnelle.</p>", unsafe_allow_html=True)

# Cr√©ation des onglets
tab1, tab2 = st.tabs(["üí¨ Assistant IA", "üìã Suivi "])

with tab1:
    st.markdown("### Posez votre question √† l'assistant")

    chat_display_container = st.container()
    with chat_display_container:
        # Affichage des messages existants
        for message in st.session_state.messages:
            avatar_icon = "üë§" if message["role"] == "user" else "ü§ñ"
            avatar_class = "user-avatar" if message["role"] == "user" else "assistant-avatar"
            content_class = "user-content" if message["role"] == "user" else "assistant-content"
            container_class = "user-message" if message["role"] == "user" else "assistant-message"

            st.markdown(f"""
                <div class="chat-container {container_class}">
                    <div class="avatar {avatar_class}">{avatar_icon}</div>
                    <div class="message-content {content_class}">
                        {message["content"]}
                    </div>
                </div>
            """, unsafe_allow_html=True)

    if prompt := st.chat_input("Posez votre question ici..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        response_data = conversation_chat(prompt)
        st.session_state.messages.append({"role": "assistant", "content": response_data["response"]})
        st.rerun()



with tab2:
        
    # Initialisation de l'√©tat de session pour stocker les candidatures
    if "candidatures" not in st.session_state:
        st.session_state.candidatures = []
    if "candidature_a_modifier" not in st.session_state:
        st.session_state.candidature_a_modifier = None

    # Fonction pour supprimer une candidature
    def supprimer_candidature(index):
        st.session_state.candidatures.pop(index)
        st.rerun()

    # Fonction pour d√©finir la candidature √† modifier
    def set_candidature_a_modifier(index):
        st.session_state.candidature_a_modifier = index
        st.rerun()

    # Fonction pour modifier une candidature existante
    def modifier_candidature(index, entreprise, poste, type_candidature, statut, date):
        st.session_state.candidatures[index].update({
            "Entreprise": entreprise,
            "Poste": poste,
            "Type": type_candidature,
            "Statut": statut,
            "Date": date.strftime("%Y-%m-%d")
        })
        st.session_state.candidature_a_modifier = None
        st.rerun()

    # Fonction pour afficher le formulaire de modification
    def afficher_formulaire_modification(index, candidature):
        with st.form(f"modification_candidature_{index}"):
            st.markdown("### ‚úèÔ∏è Modifier la Candidature")
            entreprise = st.text_input("Entreprise / √âtablissement", value=candidature["Entreprise"])
            poste = st.text_input("Poste / Formation", value=candidature["Poste"])
            type_candidature = st.selectbox(
                "Type",
                ["Stage", "Alternance", "Emploi", "Formation"],
                index=["Stage", "Alternance", "Emploi", "Formation"].index(candidature["Type"])
            )
            statut = st.selectbox(
                "Statut",
                ["En cours", "Accept√©", "Refus√©"],
                index=["En cours", "Accept√©", "Refus√©"].index(candidature["Statut"])
            )
            date = st.date_input("Date de candidature", datetime.strptime(candidature["Date"], "%Y-%m-%d"))
            
            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button("üíæ Enregistrer"):
                    if entreprise and poste:
                        modifier_candidature(index, entreprise, poste, type_candidature, statut, date)
            with col2:
                if st.form_submit_button("‚ùå Annuler"):
                    st.session_state.candidature_a_modifier = None
                    st.rerun()

    # Fonction pour afficher le tableau de bord
    def afficher_tableau():
        st.markdown("## üìã Suivi des Candidatures")
        
        if not st.session_state.candidatures:
            st.info("Aucune candidature enregistr√©e pour le moment.")
            return
        
        df = pd.DataFrame(st.session_state.candidatures)
        
        # Filtres dynamiques
        col1, col2 = st.columns(2)
        with col1:
            statut_filter = st.selectbox("Filtrer par statut", ["Tous", "En cours", "Accept√©", "Refus√©"])
        with col2:
            type_filter = st.selectbox("Filtrer par type", ["Tous", "Stage", "Alternance", "Emploi", "Formation"])
        
        filtered_df = df.copy()
        if statut_filter != "Tous":
            filtered_df = filtered_df[filtered_df["Statut"] == statut_filter]
        if type_filter != "Tous":
            filtered_df = filtered_df[filtered_df["Type"] == type_filter]
        
        # Afficher le tableau avec les boutons de modification
        st.markdown("### Liste des candidatures")
        for index, row in df.iterrows():
            with st.expander(f"{row['Entreprise']} - {row['Poste']} ({row['Statut']})"):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"**Type:** {row['Type']}")
                    st.write(f"**Date:** {row['Date']}")
                    st.write(f"**Statut:** {row['Statut']}")
                with col2:
                    if st.button("‚úèÔ∏è Modifier", key=f"edit_{index}"):
                        set_candidature_a_modifier(index)
                with col3:
                    if st.button("üóëÔ∏è Supprimer", key=f"delete_{index}"):
                        if st.button("Confirmer ‚ùå", key=f"confirm_delete_{index}"):
                            supprimer_candidature(index)
            
            # Afficher le formulaire de modification si cette candidature est s√©lectionn√©e
            if st.session_state.candidature_a_modifier == index:
                afficher_formulaire_modification(index, row)

        st.markdown("### Vue d'ensemble")
        st.dataframe(filtered_df, use_container_width=True)

    # Fonction pour ajouter une candidature
    def ajouter_candidature():
        with st.form("ajout_candidature"):
            st.markdown("### ‚ûï Ajouter une Candidature")
            entreprise = st.text_input("Entreprise / √âtablissement")
            poste = st.text_input("Poste / Formation")
            type_candidature = st.selectbox("Type", ["Stage", "Alternance", "Emploi", "Formation"])
            statut = st.selectbox("Statut", ["En cours", "Accept√©", "Refus√©"])
            date = st.date_input("Date de candidature", datetime.today())
            submit = st.form_submit_button("Ajouter")
            
            if submit and entreprise and poste:
                st.session_state.candidatures.append({
                    "Entreprise": entreprise,
                    "Poste": poste,
                    "Type": type_candidature,
                    "Statut": statut,
                    "Date": date.strftime("%Y-%m-%d")
                })
                st.success("Candidature ajout√©e avec succ√®s !")
                st.rerun()
            
    # Interface principale
    #st.set_page_config(page_title="Suivi des Candidatures", layout="wide")
    st.title("üéØ Tableau de Suivi des Candidatures")

    ajouter_candidature()
    afficher_tableau()
        

